# ollama_utils.py
import requests
import json
import logging
from typing import Optional, List

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

OLLAMA_API_BASE_URL = "http://ollama:11434/api" # Стандартная конечная точка API Ollama

def get_embedding_ollama(text: str, model: str) -> Optional[List[float]]:
    """
    Получает эмбеддинг для заданного текста с помощью Ollama.
    Предполагается, что сервер Ollama запущен, и модель скачана.
    """
    url = f"{OLLAMA_API_BASE_URL}/embeddings"
    headers = {"Content-Type": "application/json"}
    data = {
        "model": model,
        "prompt": text
    }
    try:
        response = requests.post(url, headers=headers, data=json.dumps(data))
        response.raise_for_status() # Вызывает исключение для HTTP ошибок
        return response.json()["embedding"]
    except requests.exceptions.RequestException as e:
        logging.error(f"Ошибка при получении эмбеддинга от Ollama (модель: {model}): {e}")
        return None

def classify_email(text: str, model: str) -> bool:
    """
    Классифицирует электронное письмо: является ли оно запросом в поддержку
    интернет-магазина одежды.
    Возвращает True, если релевантно, False в противном случае.
    """
    # Улучшенный промпт для классификации, с четким указанием темы магазина одежды
    prompt = (
        f"Ты — высокоточный классификатор электронных писем для службы поддержки "
        f"интернет-магазина по продаже одежды. Твоя задача — определить, относится ли "
        f"письмо *строго* к одной из следующих тем: заказы, доставка, возврат, обмен, "
        f"качество одежды, размеры, оплата, наличие товара, ассортимент, работа сайта магазина. "
        f"Если письмо не относится *напрямую* к этим темам интернет-магазина одежды, "
        f"оно считается нерелевантным. "
        f"Отвечай только одним словом: 'ДА' или 'НЕТ'. Не добавляй никаких объяснений, "
        f"знаков препинания или других символов.\n"
        f"---"
        f"\nПримеры релевантных писем (Ответ: ДА):\n"
        f"Вопрос: 'Мой заказ #12345 не пришел. Что мне делать?'\nОтвет: ДА\n"
        f"Вопрос: 'Я не могу войти в свой аккаунт, помогите!'\nОтвет: ДА\n"
        f"Вопрос: 'Привет, я нашел ошибку на вашем сайте с отображением товаров.'\nОтвет: ДА\n"
        f"Вопрос: 'Как оформить возврат футболки?'\nОтвет: ДА\n"
        f"Вопрос: 'Какой размер мне выбрать для джинсов, если мои параметры 90-70-98?'\nОтвет: ДА\n"
        f"Вопрос: 'Хочу узнать, есть ли еще в наличии та красная куртка?'\nОтвет: ДА\n"
        f"\nПримеры нерелевантных писем (Ответ: НЕТ):\n"
        f"Вопрос: 'Получите скидку 20% на следующую покупку!'\nОтвет: НЕТ\n"
        f"Вопрос: 'Уведомление: Ваш пароль был изменен. Если это были не вы, свяжитесь с нами.'\nОтвет: НЕТ\n"
        f"Вопрос: 'Подтвердите подписку на нашу рассылку.'\nОтвет: НЕТ\n"
        f"Вопрос: 'Пожалуйста, отпишите меня от рассылки.'\nОтвет: НЕТ\n"
        f"Вопрос: 'Спасибо за ваш недавний платеж.'\nОтвет: НЕТ\n"
        f"Вопрос: 'Ваш заказ #67890 отправлен.' (Это уведомление, а не запрос)\nОтвет: НЕТ\n"
        f"Вопрос: 'Проблема с подключением к Wi-Fi.'\nОтвет: НЕТ\n"
        f"Вопрос: 'Бронирование на 20 июля.'\nОтвет: НЕТ\n"
        f"Вопрос: 'Вопрос по учебной программе.'\nОтвет: НЕТ\n"
        f"---"
        f"\nАнализируемое письмо: '{text}'\nОтвет:"
    )
    url = f"{OLLAMA_API_BASE_URL}/generate"
    headers = {"Content-Type": "application/json"}
    data = {
        "model": model,
        "prompt": prompt,
        "stream": False,
        "options": {
            "temperature": 0.05, # Уменьшаем креативность еще больше для очень точной классификации
            "top_p": 0.9
        }
    }
    try:
        response = requests.post(url, headers=headers, data=json.dumps(data))
        response.raise_for_status()
        generated_text = response.json()["response"].strip().upper() # Приводим к верхнему регистру для надежности
        logging.info(f"Ollama классифицировал письмо как: '{generated_text}'")

        if generated_text == "ДА": # Уточняем проверку, чтобы было ровно "ДА"
            return True
        elif generated_text == "НЕТ": # Уточняем проверку, чтобы было ровно "НЕТ"
            return False
        else: # Если LLM ответил неоднозначно (не "ДА" и не "НЕТ"), считаем нерелевантным
            logging.warning(f"Классификация неоднозначна для письма. Ответ LLM: '{generated_text}'. Считаем нерелевантным.")
            return False
    except requests.exceptions.RequestException as e:
        logging.error(f"Ошибка при классификации письма с помощью Ollama (модель: {model}): {e}")
        return False

def generate_response_ollama(email_text: str, knowledge_base_answer: str, model: str) -> Optional[str]:
    """
    Генерирует профессиональный, понятный и вежливый ответ с помощью Ollama,
    действуя как агент поддержки интернет-магазина одежды и используя информацию из базы знаний.
    """
    prompt = (
        f"Ты — дружелюбный, профессиональный и полезный агент службы поддержки "
        f"клиентов интернет-магазина по продаже одежды. "
        f"Твоя задача — формировать полные и исчерпывающие ответы на вопросы клиентов, "
        f"основываясь ТОЛЬКО на предоставленной 'Информации из базы знаний' и 'Вопросе клиента'. "
        f"Не придумывай информацию, не домысливай и не добавляй лишних деталей, которых нет "
        f"в предоставленных источниках. "
        f"Используй информацию из базы знаний как основной источник для ответа, "
        f"максимально перефразируя ее, если необходимо, но сохраняя точный смысл. "
        f"Если предоставленной информации из базы знаний недостаточно для полного ответа "
        f"на весь вопрос клиента, извинись и вежливо предложи связаться с ними другим способом "
        f"(например, по телефону, через чат на сайте или отправить полную информацию по их запросу), "
        f"или пообещай, что специалисты свяжутся с ними позже. "
        f"Никогда не упоминай, что информация взята из базы знаний, или что ты ИИ. "
        f"Сохраняй тон вежливым, профессиональным и полезным. "
        f"Начинай ответ с приветствия, например 'Здравствуйте, ...' или 'Добрый день, ...'. "
        f"Заканчивай ответ дружелюбным предложением дальнейшей помощи или благодарностью.\n"
        f"\n---"
        f"\nВопрос клиента:\n\"{email_text}\"\n"
        f"\nИнформация из базы знаний:\n\"{knowledge_base_answer}\"\n"
        f"\n---"
        f"\nСгенерируй ответ:"
    )
    url = f"{OLLAMA_API_BASE_URL}/generate"
    headers = {"Content-Type": "application/json"}
    data = {
        "model": model,
        "prompt": prompt,
        "stream": False,
        "options": {
            "temperature": 0.4, # Слегка снижаем креативность для большей строгости
            "top_p": 0.9,
            "num_predict": 2048
        }
    }
    try:
        response = requests.post(url, headers=headers, data=json.dumps(data))
        response.raise_for_status()
        return response.json()["response"].strip()
    except requests.exceptions.RequestException as e:
        logging.error(f"Ошибка при генерации ответа с помощью Ollama (модель: {model}): {e}")
        return "Извините, произошла техническая ошибка при генерации ответа. Наши специалисты свяжутся с вами в ближайшее время."