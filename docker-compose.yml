version: '3.8'

services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama-server
    ports:
      - "11434:11434" # Порт для доступа к Ollama API
    volumes:
      - ollama_models:/root/.ollama # Для сохранения моделей
    command: > # Команда для загрузки моделей при первом запуске контейнера Ollama и затем его запуска
      bash -c "ollama pull all-minilm && ollama pull gemma:7b && ollama serve"

  app:
    build: . # Указывает Docker на использование Dockerfile в текущей директории
    container_name: ai_email_support_app
    depends_on:
      - ollama # Гарантирует, что Ollama запустится первым
    environment:
      # Передача переменных окружения из .env в контейнер
      - GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID}
      - GOOGLE_CLIENT_SECRET=${GOOGLE_CLIENT_SECRET}
      # Указываем, где искать Ollama (имя сервиса в Docker Compose)
      - OLLAMA_HOST=http://ollama:11434
    volumes:
      # Маппинг тома для token.pickle и embeddings
      - ./token.pickle:/app/token.pickle
      - ./embeddings:/app/embeddings
    command: python main.py # Команда запуска вашего приложения

volumes:
  ollama_models: # Том для сохранения моделей Ollama